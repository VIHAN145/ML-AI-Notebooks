{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WH1Pr4KQlCh"
   },
   "source": [
    "### Build a DNN using Keras with `RELU` and `ADAM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbvI8LqlQlCl"
   },
   "source": [
    "#### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1580304956193,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "RvoYeNwDg3G3",
    "outputId": "e355977c-3885-4fde-b5d4-8ec7bbc9002e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "# Loading Tensorflow version 2.0\n",
    "\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPW-a-qYQlCp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1580305016898,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "ZzAMhvnOhJi4",
    "outputId": "5e7a3175-0695-4bc9-8c67-ab7afeb3fdfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the Tensorflow version has been updatd or not.\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74cQBsi5QlCw"
   },
   "source": [
    "#### Collect Fashion mnist data from tf.keras.datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVWy0oDTr2Kj"
   },
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset and plitting into train and test.\n",
    "\n",
    "Mnist = tf.keras.datasets.fashion_mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2151,
     "status": "ok",
     "timestamp": 1580305254526,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "UHF4POBch33E",
    "outputId": "a92a3a8f-41bd-417e-8d56-5f7982520565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = Mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1580305358735,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "L1rJ3a-qiaor",
    "outputId": "bebf7876-2ec2-4d94-c4b0-7cfd6633a052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is :  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Finding out the dimensions of training and testing.\n",
    "\n",
    "print(\"The shape of x_train is : \", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 841,
     "status": "ok",
     "timestamp": 1580305403748,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "yFnymh-dij5-",
    "outputId": "fbbdf739-7c52-45bd-c7f0-7cc970863ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_test is :  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of x_test is : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1580305442153,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "l96ru6Pxij3B",
    "outputId": "c87abad5-d2ad-4bec-9db2-ff354e5a7ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of y_train :  (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of y_train : \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1580305468212,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "QnBNdAp_ijz0",
    "outputId": "2bc47e78-5135-4b6d-86cc-ef19cd57a6c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of y_test :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz9SWmYjk5yN"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1580305993732,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "1eQNQ4bGijN9",
    "outputId": "87173766-f827-4701-d8da-ac48f0966ef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   6,   7,  10,  12,  13,  15,  18,  23,\n",
       "        29,  35,  36,  40,  41,  44,  48,  52,  54,  55,  56,  57,  58,\n",
       "        61,  62,  64,  65,  66,  67,  69,  72,  73,  74,  75,  77,  80,\n",
       "        82,  88,  92,  98,  99, 102, 106, 107, 109, 115, 117, 119, 121,\n",
       "       122, 123, 127, 130, 134, 136, 141, 144, 145, 146, 150, 154, 155,\n",
       "       156, 159, 161, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173,\n",
       "       175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188,\n",
       "       189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202,\n",
       "       203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
       "       216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
       "       229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
       "       243, 244, 245, 246, 248, 249, 250, 255], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique numerical values of the first image.\n",
    "\n",
    "np.unique(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1580306022350,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "883DCEMGlAJ9",
    "outputId": "77cc4668-a340-443c-8471-79e6ce2c21e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking all numerical values of the first image.\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 929,
     "status": "ok",
     "timestamp": 1580306121981,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "nMVqDzz6k_zk",
    "outputId": "7011e703-98eb-4c6e-ff22-d042236e947b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
      "  0.         0.00392157 0.01568627 0.         0.         0.\n",
      "  0.         0.00392157 0.00392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n",
      "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
      "  0.01568627 0.         0.         0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n",
      "  0.56470588 0.48235294 0.09019608 0.         0.         0.\n",
      "  0.         0.04705882 0.03921569 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
      "  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
      "  0.30196078 0.50980392 0.28235294 0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n",
      "  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n",
      "  0.55294118 0.34509804 0.6745098  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
      "  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n",
      "  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n",
      "  0.48235294 0.76862745 0.89803922 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
      "  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
      "  0.8745098  0.96078431 0.67843137 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n",
      "  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n",
      "  0.8627451  0.95294118 0.79215686 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.01176471 0.\n",
      "  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n",
      "  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n",
      "  0.88627451 0.77254902 0.81960784 0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.02352941 0.\n",
      "  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
      "  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
      "  0.96078431 0.46666667 0.65490196 0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01568627 0.         0.\n",
      "  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n",
      "  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n",
      "  0.85098039 0.81960784 0.36078431 0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n",
      "  0.00784314 0.         0.         0.         0.         0.\n",
      "  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n",
      "  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n",
      "  0.85490196 1.         0.30196078 0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.24313725 0.56862745 0.8\n",
      "  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
      "  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
      "  0.87843137 0.95686275 0.62352941 0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902\n",
      "  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n",
      "  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n",
      "  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n",
      "  0.91372549 0.93333333 0.84313725 0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n",
      "  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n",
      "  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n",
      "  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n",
      "  0.8627451  0.90980392 0.96470588 0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
      "  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
      "  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
      "  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
      "  0.87058824 0.89411765 0.88235294 0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n",
      "  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n",
      "  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n",
      "  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n",
      "  0.8745098  0.87843137 0.89803922 0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n",
      "  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n",
      "  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n",
      "  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n",
      "  0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
      "  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
      "  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
      "  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
      "  0.70980392 0.80392157 0.80784314 0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n",
      "  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n",
      "  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n",
      "  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n",
      "  0.65490196 0.69411765 0.82352941 0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n",
      "  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n",
      "  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n",
      "  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n",
      "  0.75294118 0.84705882 0.66666667 0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
      "  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
      "  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
      "  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
      "  0.38823529 0.22745098 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n",
      "  0.1372549  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Understanding how all values will look after reducing the variance.\n",
    "\n",
    "x_c = x_train[0]/255\n",
    "print(x_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "no7aWYZyQlC1"
   },
   "source": [
    "#### Change train and test labels into one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1580306179582,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "UX6otc4wQlC2",
    "outputId": "7e3bb552-e54f-46e1-c921-3c56c0dbf6d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique(y=<tf.Tensor: shape=(10,), dtype=uint8, numpy=array([9, 0, 3, 2, 7, 5, 1, 6, 4, 8], dtype=uint8)>, idx=<tf.Tensor: shape=(60000,), dtype=int32, numpy=array([0, 1, 1, ..., 2, 1, 5], dtype=int32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values in y_train.\n",
    "\n",
    "tf.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEP_GuMElydP"
   },
   "outputs": [],
   "source": [
    "# Encoding y_train and y_test.\n",
    "\n",
    "y_train_encode = tf.keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hyjJQdiemBIT"
   },
   "outputs": [],
   "source": [
    "y_test_encode = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjNrRTdoQlC5"
   },
   "source": [
    "#### Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDJ9DHVNQlC7"
   },
   "source": [
    "#### Initialize model, reshape & normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1580306337654,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "pCDQs_g1QlC8",
    "outputId": "d8169517-f524-4e4f-af67-6b3e9686e6b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_J2EAobHmjTy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cy9CioOwmjQd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-dLUFoVmjNy"
   },
   "outputs": [],
   "source": [
    "# Normalizing the data.\n",
    "\n",
    "x_train_normalize = tf.keras.utils.normalize(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hMicqyJmixt"
   },
   "outputs": [],
   "source": [
    "x_test_normalize = tf.keras.utils.normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPziELIhnk2X"
   },
   "outputs": [],
   "source": [
    "# Reshaping and initilizing the model .\n",
    "\n",
    "model= models.Sequential([layers.Flatten(input_shape=(28,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4430,
     "status": "ok",
     "timestamp": 1580308258846,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "8lLwSSaQtf7j",
    "outputId": "81095c84-92ca-49af-f048-37a42c881c98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 7.96855248e-04, 7.97239063e-04, ...,\n",
       "       9.99989382e-01, 9.99989855e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the values have been normalized or not.\n",
    "\n",
    "np.unique(x_train_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1570,
     "status": "ok",
     "timestamp": 1580308281084,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "rNfv2u_XtoUx",
    "outputId": "c561df43-5018-426c-c709-336ee486e2d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 8.20436479e-04, 8.29325397e-04, ...,\n",
       "       9.99980949e-01, 9.99988218e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(x_test_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBGwTTilQlDD"
   },
   "source": [
    "#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXbfpfOzQlDF"
   },
   "outputs": [],
   "source": [
    "# Adding a dropout layer and two fully connected layers with 200 and 100 neurons respectively .\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(200, activation= 'relu', input_shape=(28,28)))\n",
    "model.add(layers.Dense(100, activation= 'relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5I8f5otcQlDJ"
   },
   "source": [
    "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZkvKymSd0Sr"
   },
   "outputs": [],
   "source": [
    "# Adding the final output layer.\n",
    "\n",
    "model.add(layers.Dense(10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WN-zL8XDvfhR"
   },
   "outputs": [],
   "source": [
    "# Compiling the model. \n",
    "\n",
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 275744,
     "status": "ok",
     "timestamp": 1580309283212,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "5C8TvIJKv1yl",
    "outputId": "079fa66c-09ef-4c23-eaf7-b56b3105c48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.5111 - accuracy: 0.8118 - val_loss: 0.4260 - val_accuracy: 0.8411\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3950 - accuracy: 0.8517 - val_loss: 0.3744 - val_accuracy: 0.8602\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3623 - accuracy: 0.8646 - val_loss: 0.3611 - val_accuracy: 0.8657\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3455 - accuracy: 0.8699 - val_loss: 0.3474 - val_accuracy: 0.8726\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3312 - accuracy: 0.8746 - val_loss: 0.3367 - val_accuracy: 0.8754\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3188 - accuracy: 0.8796 - val_loss: 0.3494 - val_accuracy: 0.8706\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3068 - accuracy: 0.8829 - val_loss: 0.3344 - val_accuracy: 0.8752\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3010 - accuracy: 0.8858 - val_loss: 0.3161 - val_accuracy: 0.8803\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2928 - accuracy: 0.8881 - val_loss: 0.3209 - val_accuracy: 0.8812\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2872 - accuracy: 0.8902 - val_loss: 0.3087 - val_accuracy: 0.8876\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2793 - accuracy: 0.8921 - val_loss: 0.3114 - val_accuracy: 0.8848\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2772 - accuracy: 0.8942 - val_loss: 0.3233 - val_accuracy: 0.8783\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2703 - accuracy: 0.8957 - val_loss: 0.3074 - val_accuracy: 0.8907\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2665 - accuracy: 0.8970 - val_loss: 0.3055 - val_accuracy: 0.8911\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2640 - accuracy: 0.8977 - val_loss: 0.3049 - val_accuracy: 0.8891\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2553 - accuracy: 0.9009 - val_loss: 0.3110 - val_accuracy: 0.8905\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2572 - accuracy: 0.8997 - val_loss: 0.3129 - val_accuracy: 0.8841\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2535 - accuracy: 0.9027 - val_loss: 0.3103 - val_accuracy: 0.8899\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2476 - accuracy: 0.9041 - val_loss: 0.3060 - val_accuracy: 0.8913\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s 92us/sample - loss: 0.2480 - accuracy: 0.9050 - val_loss: 0.3309 - val_accuracy: 0.8778\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2438 - accuracy: 0.9070 - val_loss: 0.3183 - val_accuracy: 0.8904\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2420 - accuracy: 0.9068 - val_loss: 0.3036 - val_accuracy: 0.8923\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2373 - accuracy: 0.9081 - val_loss: 0.3113 - val_accuracy: 0.8899\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2348 - accuracy: 0.9082 - val_loss: 0.3121 - val_accuracy: 0.8895\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2333 - accuracy: 0.9092 - val_loss: 0.3163 - val_accuracy: 0.8882\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2327 - accuracy: 0.9101 - val_loss: 0.3055 - val_accuracy: 0.8956\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2298 - accuracy: 0.9113 - val_loss: 0.3073 - val_accuracy: 0.8924\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2283 - accuracy: 0.9115 - val_loss: 0.3212 - val_accuracy: 0.8912\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2272 - accuracy: 0.9115 - val_loss: 0.3184 - val_accuracy: 0.8916\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2244 - accuracy: 0.9139 - val_loss: 0.3135 - val_accuracy: 0.8921\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2214 - accuracy: 0.9137 - val_loss: 0.3025 - val_accuracy: 0.8949\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2178 - accuracy: 0.9159 - val_loss: 0.2933 - val_accuracy: 0.8961\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2159 - accuracy: 0.9156 - val_loss: 0.3120 - val_accuracy: 0.8927\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2160 - accuracy: 0.9152 - val_loss: 0.3093 - val_accuracy: 0.8921\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2141 - accuracy: 0.9162 - val_loss: 0.3095 - val_accuracy: 0.8940\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2151 - accuracy: 0.9157 - val_loss: 0.3096 - val_accuracy: 0.8942\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2144 - accuracy: 0.9162 - val_loss: 0.3169 - val_accuracy: 0.8926\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2109 - accuracy: 0.9184 - val_loss: 0.3240 - val_accuracy: 0.8911\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2108 - accuracy: 0.9183 - val_loss: 0.3200 - val_accuracy: 0.8948\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2097 - accuracy: 0.9189 - val_loss: 0.3235 - val_accuracy: 0.8928\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2105 - accuracy: 0.9186 - val_loss: 0.3174 - val_accuracy: 0.8965\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2072 - accuracy: 0.9199 - val_loss: 0.3187 - val_accuracy: 0.8947\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2082 - accuracy: 0.9190 - val_loss: 0.3116 - val_accuracy: 0.8953\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2041 - accuracy: 0.9211 - val_loss: 0.3276 - val_accuracy: 0.8918\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2009 - accuracy: 0.9214 - val_loss: 0.3230 - val_accuracy: 0.8918\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2042 - accuracy: 0.9200 - val_loss: 0.3269 - val_accuracy: 0.8916\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2035 - accuracy: 0.9208 - val_loss: 0.3412 - val_accuracy: 0.8906\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2025 - accuracy: 0.9220 - val_loss: 0.3356 - val_accuracy: 0.8912\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1996 - accuracy: 0.9229 - val_loss: 0.3139 - val_accuracy: 0.8948\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1999 - accuracy: 0.9225 - val_loss: 0.3115 - val_accuracy: 0.8923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f38400a0240>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model to check how the model is performing. \n",
    "\n",
    "model.fit(x_train_normalize, y_train_encode, epochs=50, validation_data=(x_test_normalize, y_test_encode), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4422,
     "status": "ok",
     "timestamp": 1580309543855,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "C4HDq-8Twcwj",
    "outputId": "b11709c7-17cc-40de-dbfd-af6e1421c1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1467 - accuracy: 0.9455\n",
      "The training loss is 14.673697718828915% and The training accuracy is 94.54500079154968%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on training set. \n",
    "\n",
    "evaluate = model.evaluate(x_train_normalize, y_train_encode)\n",
    "print('The training loss is {}% and The training accuracy is {}%'.format(evaluate[0]*100, evaluate[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1549,
     "status": "ok",
     "timestamp": 1580309711163,
     "user": {
      "displayName": "Vihan Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB-QDJ3uw_nBr4rpbujiTNitDCQnCZ_B2aXFBjbFQ=s64",
      "userId": "11448973563679387390"
     },
     "user_tz": -330
    },
    "id": "_JpXmeKbyen2",
    "outputId": "bad18519-e372-41a8-d579-b27bf54c2953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.3115 - accuracy: 0.8923\n",
      "The test loss is 31.153352382183076% and The test accuracy is 94.54500079154968%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set.\n",
    "\n",
    "evaluate1= model.evaluate(x_test_normalize, y_test_encode)\n",
    "print('The test loss is {}% and The test accuracy is {}%'.format(evaluate1[0]*100, evaluate[1]*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnZsnZECzILd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "download.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
